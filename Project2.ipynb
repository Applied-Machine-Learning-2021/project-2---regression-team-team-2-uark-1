{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Complete_Data_Prediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "copyright"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python [conda env:root] *",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.16"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google/applied-machine-learning-intensive/blob/master/content/03_regression/09_regression_project/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2020 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSdG7cSNFro-"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FdRu8E0F6EJ"
      },
      "source": [
        "# Regression Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm5d3zEpKE00"
      },
      "source": [
        "We have learned about regression and how to build regression models using both scikit-learn and TensorFlow. Now we'll build a regression model from start to finish. We will acquire data and perform exploratory data analysis and data preprocessing. We'll build and tune our model and measure how well our model generalizes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iIQ-XduKJZz"
      },
      "source": [
        "## Framing the Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY3OnPx1zGWa"
      },
      "source": [
        "### Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JbgK7HnzJD_"
      },
      "source": [
        "*Friendly Insurance, Inc.* has requested we do a study for them to help predict the cost of their policyholders. They have provided us with sample [anonymous data](https://www.kaggle.com/mirichoi0218/insurance) about some of their policyholders for the previous year. The dataset includes the following information:\n",
        "\n",
        "Column   | Description\n",
        "---------|-------------\n",
        "age      | age of primary beneficiary\n",
        "sex      | gender of the primary beneficiary (male or female)\n",
        "bmi      | body mass index of the primary beneficiary\n",
        "children | number of children covered by the plan\n",
        "smoker   | is the primary beneficiary a smoker (yes or no)\n",
        "region   | geographic region of the beneficiaries (northeast, southeast, southwest, or northwest)\n",
        "charges  | costs to the insurance company\n",
        "\n",
        "We have been asked to create a model that, given the first six columns, can predict the charges the insurance company might incur.\n",
        "\n",
        "The company wants to see how accurate we can get with our predictions. If we can make a case for our model, they will provide us with the full dataset of all of their customers for the last ten years to see if we can improve on our model and possibly even predict cost per client year over year."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqKI2KIe02wc"
      },
      "source": [
        "### Exercise 1: Thinking About the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjnbH6vp1PEK"
      },
      "source": [
        "#### Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhcs4Keh1Shq"
      },
      "source": [
        "Is this problem actually a good fit for machine learning? Why or why not?\n",
        "\n",
        "##### **Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhYunBlz1ZMn"
      },
      "source": [
        "### *Reponse: Since the variety of the categories are not broad enough, which means that the model we build will contain many biases. Nevertheless, the old data for charges are possibly decided by human decision, which will lead to more bias when use the model to predict the price.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJgwg-dL1cKm"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q9C-k7o4A2g"
      },
      "source": [
        "#### Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4F3Ezrc4DRb"
      },
      "source": [
        "If we do build the machine learning model, what biases might exist in the data? Is there anything that might cause the model to have trouble generalizing to other data? If so, how might we make the model more resilient?\n",
        "\n",
        "##### **Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grZRXJkr4Myz"
      },
      "source": [
        "### *Reponse: Since the data we are using to build the model does not contain clients' medical record and their income, then this will cause potential bias. Medical Record: Assume the client has had surgery in the past, yet their medical record are not requiered upon the enrollment for the insurance. Income: how much should the insurance company charge the clients should based on the clients' incomes.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMk4NdcZ4PyG"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LtrUiMk4wIg"
      },
      "source": [
        "#### Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHHdnVjS446h"
      },
      "source": [
        "We have been asked to take input features about people who are insured and predict costs, but we haven't been given much information about how these predictions will be used. What effect might our predictions have on decisions made by the insurance company? How might this affect the insured?\n",
        "\n",
        "##### **Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6tiq72L5Q11"
      },
      "source": [
        "### *Since the model is trained based on the given categories, and if in the near future, the insurance company tries to use the model we've built based on the given categories to predict the price with additional categories, the prediction for the price will be not accurate.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LojR01P5TYf"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVqj4S4tytvn"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAr2H2CJ60WX"
      },
      "source": [
        "Now that we have considered the societal implications of our model, we can start looking at the data to get a better understanding of what we are working with.\n",
        "\n",
        "The data we'll be using for this project can be [found on Kaggle](https://www.kaggle.com/mirichoi0218/insurance). Upload your `kaggle.json` file and run the code block below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiXw-ACkKlCT"
      },
      "source": [
        "! chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && mv kaggle.json ~/.kaggle/ && echo 'Done'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n85P3WhnzSmo"
      },
      "source": [
        "### Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOrjgEKuzBI6"
      },
      "source": [
        "! kaggle datasets download mirichoi0218/insurance\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpYSfwuT8N3B"
      },
      "source": [
        "### Exercise 2: EDA and Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgjffxoV7kxc"
      },
      "source": [
        "Using as many code and text blocks as you need, download the dataset, explore it, and do any model-independent preprocessing that you think is necessary. Feel free to use any of the tools for data analysis and visualization that we have covered in this course so far. Be sure to do individual column analysis and cross-column analysis. Explain your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIfb22Iq8Asx"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_F2WdDewMET"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFpRajNywKqS"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XvBzxmMzqkH"
      },
      "source": [
        "### Load Data to Python Object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk3q6P7q8D_V"
      },
      "source": [
        "insurance_df = pd.read_csv('insurance.zip')\n",
        "insurance_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eczR_Nxj4Yil"
      },
      "source": [
        "### One-hot encoding for Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UEWaUSD5E-D"
      },
      "source": [
        "#sex encoding\n",
        "#insurance_df.loc[insurance_df['sex'] == 'female', 'sex'] = 1\n",
        "#insurance_df.loc[insurance_df['sex'] == 'male', 'sex'] = 0\n",
        "#smoker encoding\n",
        "#insurance_df.loc[insurance_df['smoker'] == 'yes', 'smoker'] = 1\n",
        "#insurance_df.loc[insurance_df['smoker'] == 'no', 'smoker'] = 0\n",
        "#region encoding\n",
        "\n",
        "#sorted(insurance_df['region'].unique())\n",
        "#target_column = 'charges'\n",
        "\n",
        "#feature_columns = [c for c in insurance_df.columns if c != target_column]\n",
        "#numeric_feature_columns = [c for c in feature_columns if c != 'region']\n",
        "#target_column, feature_columns, numeric_feature_columns\n",
        "#for reg in sorted(insurance_df['region'].unique()):\n",
        "  #insurance_df[reg] = (insurance_df['region'] == reg).astype(int)\n",
        "  #feature_columns.append(reg)\n",
        "#feature_columns.remove('region')\n",
        "\n",
        "#insurance_df\n",
        "\n",
        "insurance_df = pd.get_dummies(insurance_df)\n",
        "insurance_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKX8rgX7U3rJ"
      },
      "source": [
        "### Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzqKv8ABVCLc"
      },
      "source": [
        "sns.heatmap(insurance_df.corr())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZPQ5zOz2rfQ"
      },
      "source": [
        "### Explore Data Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtlhHRw82uAL"
      },
      "source": [
        "insurance_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUo4DgfD8T7B"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac-YMzcBy1yM"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp3TkmalNcR-"
      },
      "source": [
        "Now that we understand our data a little better, we can build a model. We are trying to predict 'charges', which is a continuous variable. We'll use a regression model to predict 'charges'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmlwZpbUIHQZ"
      },
      "source": [
        "### Exercise 3: Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSQ4f2eFUnXM"
      },
      "source": [
        "### Import TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO7jze7AUquI"
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnc7Y47bIQG5"
      },
      "source": [
        "Using as many code and text blocks as you need, build a model that can predict 'charges' given the features that we have available. To do this, feel free to use any of the toolkits and models that we have explored so far.\n",
        "\n",
        "You'll be expected to:\n",
        "1. Prepare the data for the model (or models) that you choose. Remember that some of the data is categorical. In order for your model to use it, you'll need to convert the data to some numeric representation.\n",
        "1. Build a model or models and adjust parameters.\n",
        "1. Validate your model with holdout data. Hold out some percentage of your data (10-20%), and use it as a final validation of your model. Print the root mean squared error. We were able to get an RMSE between `3500` and `4000`, but your final RMSE will likely be different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjSCGA7HryJh"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD4ooxJtWuDy"
      },
      "source": [
        "### Target, Feature, Numeric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCPW0oN8W00_"
      },
      "source": [
        "target_column = 'charges'\n",
        "feature_columns = [c for c in insurance_df.columns if c != target_column]\n",
        "\n",
        "target_column, feature_columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvxF6OdwXTiM"
      },
      "source": [
        "### Target Factor to Reduce Training Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoHIU2EDXXCQ"
      },
      "source": [
        "TARGET_FACTOR = 10000\n",
        "\n",
        "insurance_df[target_column] /= TARGET_FACTOR\n",
        "\n",
        "insurance_df[target_column].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC7njPoDXynz"
      },
      "source": [
        "### Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sSpWojeXxZK"
      },
      "source": [
        "insurance_df.loc[:, feature_columns] = (insurance_df[feature_columns] - insurance_df[feature_columns].mean()) / (insurance_df[feature_columns].std())\n",
        "\n",
        "insurance_df[feature_columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjUq4IubYi-f"
      },
      "source": [
        "### Splitting Data to data_train, data_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vKuA9b4YsyC"
      },
      "source": [
        "# Your Code Goes Here\n",
        "insurance_df = insurance_df.sample(frac=1)\n",
        "test_set_size = int(len(insurance_df) * 0.2)\n",
        "#training_df0.8, testing_df0.2\n",
        "data_test = insurance_df[:test_set_size]\n",
        "data_train = insurance_df[test_set_size:]\n",
        "\n",
        "print(f'Holding out {len(data_test)} records for testing. ')\n",
        "print(f'Using {len(data_train)} records for training.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLA4Ma_6ZsND"
      },
      "source": [
        "### Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnSdx_jjZuZl"
      },
      "source": [
        "# Create the Sequential model.\n",
        "model = keras.Sequential()\n",
        "# Determine the \"input shape\", which is the number\n",
        "# of features that we will feed into the model.\n",
        "input_shape = len(feature_columns)\n",
        "# Create a layer that accepts our features and outputs\n",
        "# a single value, the predicted median home price.\n",
        "layer = layers.Dense(1, input_shape=[input_shape])\n",
        "# Add the layer to our model.\n",
        "model.add(layer)\n",
        "# Print out a model summary.\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eOiT4hnaEAK"
      },
      "source": [
        "### Making Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYgH88TMaHtx"
      },
      "source": [
        "feature_count = len(feature_columns)\n",
        "\n",
        "model = keras.Sequential([\n",
        "  layers.Dense(256, input_shape=[feature_count], activation='relu'),\n",
        "  layers.Dense(256, activation='relu'),\n",
        "  layers.Dense(1, activation='relu')\n",
        "])\n",
        "\n",
        "#four layers: first dense has two\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(\n",
        "  loss='mse',\n",
        "  optimizer='Adam',\n",
        "  metrics=['mae', 'mse'],\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2WXjupHad0X"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9iTqNbaahv4"
      },
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "history = model.fit(\n",
        "  data_train[feature_columns],\n",
        "  data_train[target_column],\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=0.2,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbGPv7gra5wU"
      },
      "source": [
        "### Validate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zl0Qs3Oa-Hf"
      },
      "source": [
        "predictions = model.predict(data_test[feature_columns])\n",
        "#predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvr7tM1ObDFu"
      },
      "source": [
        "### RMSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLuuTbGhbE3F"
      },
      "source": [
        "# Your Code Goes here\n",
        "import math\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "mean_squared_error = metrics.mean_squared_error(\n",
        "    np.array(predictions) * TARGET_FACTOR,\n",
        "    data_test[target_column] * TARGET_FACTOR\n",
        ")\n",
        "print(\"Mean Squared Error (on training data): %0.3f\" % mean_squared_error)\n",
        "\n",
        "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
        "print(\"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Sm-HIs5IL3F"
      },
      "source": [
        "# Add code and text blocks to build and validate a model and explain your work\n",
        "x = [i for i in range(0, EPOCHS)]\n",
        "val_mse = history.history['val_mse']\n",
        "mse = history.history['mse']\n",
        "\n",
        "\n",
        "plt.title(\"Error Plot\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE\")\n",
        "\n",
        "plt.plot(\n",
        "    x, mse, 'b-',\n",
        "    x, val_mse, 'r-'\n",
        ")\n",
        "\n",
        "plt.legend([\"Mean Square Error\", \"Validation Mean Square Error\"])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITsTAJgWIJVT"
      },
      "source": [
        "---"
      ]
    }
  ]
}